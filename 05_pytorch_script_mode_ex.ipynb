{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUIQh2cy6+WLPyvJZuoA+L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/torrhen/pytorch/blob/main/05_pytorch_script_mode_ex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  import os\n",
        "  # create new folder for storing modular files\n",
        "  os.makedirs('script_mode', exist_ok=True)\n",
        "\n",
        "  !pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiBNSb-M-HGS",
        "outputId": "28efa9ce-1e8a-4ee5-f3f0-f47b91760c6a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.8/dist-packages (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# script for downloading and extracting image data sets\n",
        "%%writefile script_mode/get_data.py\n",
        "import os\n",
        "import zipfile # file extracting\n",
        "from pathlib import Path # file management\n",
        "import requests # HTTP requests\n",
        "\n",
        "def download_and_extract_data(url, folder_name):\n",
        "  # store file paths\n",
        "  data_path = Path('data/')\n",
        "  image_path = data_path / folder_name\n",
        "\n",
        "  # create the image pth folder if it does not exist\n",
        "  if image_path.is_dir():\n",
        "    print(f\"{image_path} already exists.\")\n",
        "  else:\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # download image zip file from GitHub\n",
        "    with open(data_path / folder_name / \".zip\", 'wb') as f:\n",
        "      response = requests.get(url)\n",
        "      f.write(response.content)\n",
        "\n",
        "    # extract images from image zip file\n",
        "    with zipfile.ZipFile(data_path / folder_name / \".zip\", 'r') as z:\n",
        "      z.extractall(image_path)\n",
        "\n",
        "    # delete download image zip file - no longer required\n",
        "    os.remove(data_path / folder_name / \".zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLr1Uy6NDxpq",
        "outputId": "6eaa2b01-6236-45bd-8674-134085fc2248"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting script_mode/get_data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# script for creating the train and test datasets and data loaders from extracted image folders\n",
        "%%writefile script_mode/data.py\n",
        "\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "def create_dataloaders(train_dir: str, test_dir: str, transform: transforms.Compose, batch_size: int, num_workers: int = os.cpu_count()):\n",
        "  # create datasets from image file folder and apply transform\n",
        "  train_data = datasets.ImageFolder(root=train_dir, transform=transform, target_transform=None)\n",
        "  test_data = datasets.ImageFolder(root=test_dir, transform=transform, target_transform=None)\n",
        "\n",
        "  # divide the datasets into batches and shuffle if applicable\n",
        "  train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "  test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "  return train_loader, test_loader, train_data.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bukpix2bJ77G",
        "outputId": "f6b6f9f1-8007-4ccf-9e0d-add2eca900c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting script_mode/data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# script for defining the architecture of the neural network models\n",
        "%%writefile script_mode/model.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "  def __init__(self, input_size, hidden_units, output_size):\n",
        "    super().__init__()\n",
        "    self.block1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_size, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.block2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*13*13, out_features=output_size)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.fc(self.block2(self.block1(x)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8LW9xF3TxT8",
        "outputId": "9b431bb2-6b4a-4982-f310-d9f63c0389d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting script_mode/model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# script for training and evaluating a model at every epoch\n",
        "%%writefile script_mode/train.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "def train_step(model: nn.Module,\n",
        "               dataloader: DataLoader,\n",
        "               loss_fn: nn.Module,\n",
        "               accuracy_fn: Accuracy,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device):\n",
        "  \n",
        "  train_loss, train_acc = 0.0, 0.0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    # allocate to device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    # forward pass\n",
        "    logits = model(X)\n",
        "    labels = torch.argmax(torch.softmax(logits, dim=1), dim=1)\n",
        "    # calculate loss\n",
        "    loss = loss_fn(logits, y)\n",
        "    train_loss += loss\n",
        "    # calculate accuracy\n",
        "    acc = accuracy_fn(labels, y)\n",
        "    train_acc += acc\n",
        "\n",
        "    # stop accumulation of gradients\n",
        "    optimizer.zero_grad()\n",
        "    # backpropagation\n",
        "    loss.backward()\n",
        "    # gradient descent update\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(dataloader)\n",
        "  train_acc /= len(dataloader)\n",
        "\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model: nn.Module,\n",
        "              dataloader: DataLoader,\n",
        "              loss_fn: nn.Module,\n",
        "              accuracy_fn: Accuracy,\n",
        "              device: torch.device):\n",
        "  \n",
        "  test_loss, test_acc = 0.0, 0.0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      # allocate to device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      # forward pass\n",
        "      logits = model(X)\n",
        "      labels = torch.argmax(torch.softmax(logits, dim=1), dim=1)\n",
        "      # calculate loss\n",
        "      loss = loss_fn(logits, y)\n",
        "      test_loss += loss\n",
        "      # calculate accuracy\n",
        "      acc = accuracy_fn(labels, y)\n",
        "      test_acc += acc\n",
        "\n",
        "    test_loss /= len(dataloader)\n",
        "    test_acc /= len(dataloader)\n",
        "\n",
        "  return test_loss, test_acc\n",
        "\n",
        "def train(model: nn.Module,\n",
        "          train_loader: DataLoader,\n",
        "          test_loader: DataLoader,\n",
        "          loss_fn: nn.Module,\n",
        "          accuracy_fn: Accuracy,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          device:  torch.device,\n",
        "          epochs: int = 5):\n",
        "  \n",
        "  results = {'train_loss':[],\n",
        "             'train_acc':[],\n",
        "             'test_loss':[],\n",
        "             'test_acc':[]}\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    # train the model on the training data\n",
        "    train_loss, train_acc = train_step(model, train_loader, loss_fn, accuracy_fn, optimizer, device)\n",
        "    # test the model on the test data\n",
        "    test_loss, test_acc = test_step(model, test_loader, loss_fn, accuracy_fn, device)\n",
        "\n",
        "    # print results for each epoch\n",
        "    print(f\"Epoch: {epoch+1} | Train Loss: {train_loss:.5f} | Train Accuracy: {train_acc:.2f} | Test Loss: {test_loss:.5f} | Test Accuracy: {test_acc:.2f}\")\n",
        "\n",
        "    # store the results for each epoch\n",
        "    results['train_loss'].append(train_loss)\n",
        "    results['train_acc'].append(train_acc)\n",
        "    results['test_loss'].append(test_loss)\n",
        "    results['test_acc'].append(test_acc)\n",
        "  \n",
        "  return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QryKOJP26HyB",
        "outputId": "d155648a-c4fb-4d19-c6df-468414de01e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting script_mode/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# script for saving and loading trained models\n",
        "%%writefile script_mode/utils.py\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "def save_model(model: torch.nn.Module,\n",
        "               target_folder: str,\n",
        "               model_name: str):\n",
        "  \n",
        "  # store file path to save model\n",
        "  target_folder_path = Path(target_folder)\n",
        "  # create folder where model will be saved\n",
        "  target_folder_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  save_path = target_folder_path / model_name\n",
        "  # save model to save path\n",
        "  torch.save(obj=model.state_dict(), f=save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKzHA7-jVmTp",
        "outputId": "18f21f96-a8ab-4635-a37b-92a476063dce"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting script_mode/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# main script for training a neural network\n",
        "%%writefile script_mode/main.py\n",
        "import argparse\n",
        "import torch\n",
        "import os\n",
        "from torchvision import transforms\n",
        "import get_data, data, model, train, utils\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "# parse program arguments\n",
        "parser = argparse.ArgumentParser(prog='05_pytorch_script_mode_exercises')\n",
        "parser.add_argument('--TRAIN_FOLDER', action='store', default='data/pizza_steak_sushi/train')\n",
        "parser.add_argument('--TEST_FOLDER', action='store', default='data/pizza_steak_sushi/test')\n",
        "parser.add_argument('--LEARNING_RATE', action='store', default=0.001, type=float)\n",
        "parser.add_argument('--BATCH_SIZE', action='store', default=32, type=int)\n",
        "parser.add_argument('--NUM_EPOCHS', action='store', default=5, type=int)\n",
        "parser.add_argument('--HIDDEN_UNITS', action='store', default=10, type=int)\n",
        "# store the arguments\n",
        "args = parser.parse_args()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "get_data.download_and_extract_data(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\", \"pizza_steak_sushi\")\n",
        "\n",
        "# setup transform to be applied when creating data loaders\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor()\n",
        "    ]\n",
        ")\n",
        "# create data loaders for training and test data\n",
        "train_loader, test_loader, classes = data.create_dataloaders(args.TRAIN_FOLDER, \n",
        "                                                             args.TEST_FOLDER, \n",
        "                                                             transform, \n",
        "                                                             args.BATCH_SIZE)\n",
        "\n",
        "# create model\n",
        "torch.manual_seed(42)\n",
        "model1 = model.TinyVGG(3, args.HIDDEN_UNITS, 3).to(device) # allocate to device\n",
        "\n",
        "# create accuracy function\n",
        "accuracy_fn = Accuracy(task='multiclass', num_classes=3)\n",
        "\n",
        "# multiclass cross entropy loss\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "# Adam optimizer\n",
        "optimizer = torch.optim.Adam(params=model1.parameters(), lr=args.LEARNING_RATE)\n",
        "\n",
        "# train the model\n",
        "model1_results = train.train(model1, train_loader, test_loader, loss_fn, accuracy_fn, optimizer, device, args.NUM_EPOCHS)\n",
        "\n",
        "# save the model\n",
        "utils.save_model(model1, 'models', 'model1.pth')"
      ],
      "metadata": {
        "id": "V7f80p5-DNeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8acf449-ffa1-47a3-e68e-78a1c5b57f59"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting script_mode/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run in terminal\n",
        "!python script_mode/main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyX5DUlJchQt",
        "outputId": "d48eb831-4087-4d93-f702-27fe706911b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi already exists.\n",
            "Epoch: 1 | Train Loss: 1.10634 | Train Accuracy: 0.30 | Test Loss: 1.09832 | Test Accuracy: 0.29\n",
            "Epoch: 2 | Train Loss: 1.09951 | Train Accuracy: 0.33 | Test Loss: 1.06984 | Test Accuracy: 0.54\n",
            "Epoch: 3 | Train Loss: 1.08625 | Train Accuracy: 0.49 | Test Loss: 1.07999 | Test Accuracy: 0.52\n",
            "Epoch: 4 | Train Loss: 1.08246 | Train Accuracy: 0.41 | Test Loss: 1.05990 | Test Accuracy: 0.57\n",
            "Epoch: 5 | Train Loss: 1.06301 | Train Accuracy: 0.41 | Test Loss: 1.06117 | Test Accuracy: 0.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# script for predicting the label for a custom image\n",
        "%%writefile script_mode/predict.py\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import model, utils\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# read in program arguments\n",
        "parser = argparse.ArgumentParser(prog='predict the class of a custom image')\n",
        "parser.add_argument('--image_path', action='store')\n",
        "args = parser.parse_args()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# display image using PIL\n",
        "if args.image_path is not None:\n",
        "  # create tensor of image\n",
        "  img_tensor = torchvision.io.read_image(str(args.image_path)).type(torch.float32)\n",
        "  # normalize\n",
        "  img_tensor /= 255\n",
        "  # resize image using transform\n",
        "  resize_transform = transforms.Resize((64, 64))\n",
        "  img_tensor = resize_transform(img_tensor)\n",
        "  # add single batch dimension and allocate to device\n",
        "  img_tensor = img_tensor.unsqueeze(dim=0).to(device)\n",
        "\n",
        "  # load previously saved model\n",
        "  new_model = model.TinyVGG(3, 10, 3)\n",
        "  new_model.load_state_dict(torch.load(f='models/model1.pth'))\n",
        "  new_model = new_model.to(device)\n",
        "\n",
        "  new_model.eval()\n",
        "  with torch.inference_mode():\n",
        "    prediction_logits = new_model(img_tensor)\n",
        "    prediction_labels = torch.argmax(torch.softmax(prediction_logits, dim=1), dim=1)\n",
        "\n",
        "  print(f\"Prediction: {prediction_labels.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPL1JghWIcHO",
        "outputId": "c0dcfbad-bd59-4a26-e48b-9b9b1a36fcb7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting script_mode/predict.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python script_mode/predict.py --image steak.jpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u56terQRVHei",
        "outputId": "0356269e-40d5-400e-c1e2-21ebaadfdf14"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 2\n"
          ]
        }
      ]
    }
  ]
}