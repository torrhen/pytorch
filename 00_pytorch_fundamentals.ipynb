{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4I0P+C/TpWHZO0CCYjzjO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/torrhen/pytorch/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHuxDmmTc77m",
        "outputId": "6bf06d66-5c43-491e-cdc9-0b165463aa99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n",
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "# summary of available GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.tensor for tensor attributes and functions\n",
        "# scalars\n",
        "# scalars and tensors variables with rank less than 2 are lower case stylistically\n",
        "x = torch.tensor(10)\n",
        "print(x)\n",
        "y = torch.tensor(20)\n",
        "print(y)\n",
        "z = torch.tensor(5)\n",
        "print(z)\n",
        "# return value of tensor scalar as python integer\n",
        "print(x.item()) # can only be used for rank 0 tensors (scalars)\n",
        "print(y.item())\n",
        "print(z.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG38UIG_dcdK",
        "outputId": "0c73672f-60a8-4059-a6df-d19ab2e9112f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10)\n",
            "tensor(20)\n",
            "tensor(5)\n",
            "10\n",
            "20\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vector\n",
        "x_vec = torch.tensor([10, 20]) # remember the []'s\n",
        "print(x)\n",
        "print(x_vec)\n",
        "# ndim returns the number of dimensins (rank) of a tensor\n",
        "print(\"rank of x:\\t\", x.ndim) # ndim is alias for dim() method\n",
        "print(\"rank of x_vec:\\t\", x_vec.ndim)\n",
        "# NUMBER OF NESTED BRACKETS []'s\n",
        "\n",
        "print(\"shape of x_vec\\t\", x_vec.shape) # number of elements along each dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R6ULMLdfzCa",
        "outputId": "a0c4b7ba-208f-46e8-fadc-de65d3714993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10)\n",
            "tensor([10, 20])\n",
            "rank of x:\t 0\n",
            "rank of x_vec:\t 1\n",
            "shape of x_vec\t torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix\n",
        "# matrices and tensor variables with a rank greater than 1 are upper case stylistically\n",
        "X_MAT = torch.tensor([[2, 4],\n",
        "                      [6, 8],\n",
        "                      [10, 12]]) # rank 2 (ndim = 2)\n",
        "print(X_MAT)\n",
        "print(\"x_mat shape:\\t\", X_MAT.shape) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz6fbmwUhtv2",
        "outputId": "f282c6c6-6e80-40af-e4d3-73d3c39988ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2,  4],\n",
            "        [ 6,  8],\n",
            "        [10, 12]])\n",
            "x_mat shape:\t torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor\n",
        "X_TEN = torch.tensor([[[1, 2, 3, 4],\n",
        "                       [5, 6, 7, 8]], \n",
        "                      [[8, 7, 6, 5],\n",
        "                       [4, 3, 2, 1]]])\n",
        "print(\"x_ten rank:\\t\", X_TEN.ndim) # 3\n",
        "print(\"x_ten shape:\\t\", X_TEN.shape) # [2, 2, 4]\n",
        "\n",
        "# errors can occur when operating on two or more tensors with incompatible shapes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDJmLiJFiiH7",
        "outputId": "44d89528-d5a1-4639-c644-ab826bf57d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_ten rank:\t 3\n",
            "x_ten shape:\t torch.Size([2, 2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a random tensor\n",
        "r = torch.rand(5, 5) # uniform distribution [0, 1)\n",
        "# r = torch.rand(size=(5, 5)) is the same tensor\n",
        "print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCP4katGkPvr",
        "outputId": "d89a6923-0e52-4ee2-8a9f-be283e76c6d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6309, 0.5231, 0.2305, 0.2840, 0.1543],\n",
            "        [0.2422, 0.5006, 0.6026, 0.1476, 0.2363],\n",
            "        [0.6203, 0.5524, 0.7048, 0.5440, 0.4113],\n",
            "        [0.0422, 0.1145, 0.0020, 0.3196, 0.3239],\n",
            "        [0.1509, 0.0417, 0.6831, 0.0499, 0.2133]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a zeros tensor\n",
        "z = torch.zeros(size=(2, 3))\n",
        "print(z)\n",
        "# create a ones tensor\n",
        "o = torch.ones(size=(4, 5))\n",
        "print(o)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG5ldn2vpGov",
        "outputId": "4b5ad8d3-c738-49d1-b2ca-67e86722d4ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tensor from range or sequence of values\n",
        "a = torch.range(0, 5) # deprecated 0, 1, 2, 3, 4, 5 [start, end](inconsistent with python ranges)\n",
        "print(a)\n",
        "b = torch.arange(1, 11) # use this instead, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 [start, end)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1lPh1kpp4B0",
        "outputId": "db5b63cb-29c0-469d-eea0-8ad02edd3264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1., 2., 3., 4., 5.])\n",
            "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tensor using the shape of another tensor\n",
        "# create a tensor of zeros with the same shape as b (above)\n",
        "z_like = torch.zeros_like(b)\n",
        "print(z_like)\n",
        "# create a tensor of ones with the same shape as b (above)\n",
        "o_like = torch.ones_like(b)\n",
        "print(o_like)\n",
        "# create an empty tensor with the same shape as b (above)\n",
        "e_like = torch.empty_like(b)\n",
        "print(e_like) # uninitialized, undefined values\n",
        "# create a tensor full of a specific value with the same shape as b (above)\n",
        "f_like = torch.full_like(b, 5)\n",
        "print(f_like)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rdPWKBAseB5",
        "outputId": "482421b9-c5b0-450e-ce26-b1cd69eecaee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([98189056,        0,        0,        0,        0,        0,        0,\n",
            "               0,        0,        0])\n",
            "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor data type\n",
        "# default data type for all float tensors in PyTorch is float32, regardless if None is specified\n",
        "x_float32 = torch.tensor([1.0, 2.0, 3.0, 4.0], dtype=None)\n",
        "print(x_float32.dtype) # float32 single precision\n",
        "\n",
        "x_float16 = torch.tensor([1.0, 2.0, 3.0, 4.0], dtype=torch.float16)\n",
        "print(x_float16.dtype) # float16 half precision\n",
        "\n",
        "# it is faster to calculate operations on numerical values with smaller precision\n",
        "\n",
        "# errors MAY occur when operating on two or more tensors with different precisions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygVSfaCft0ar",
        "outputId": "7f648259-5629-4002-dec7-85b1f4e18b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor devices\n",
        "x_cpu = torch.tensor([1, 2, 3]) # device is 'cpu' by default\n",
        "#x_gpu = torch.tensor([1, 2, 3], device='cuda') # hardware option must be selected\n",
        "\n",
        "print(x_cpu.device) # cpu\n",
        "#print(x_gpu.device) # cuda:0\n",
        "\n",
        "# errors occur when operating on two or more tensors stored on different devices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onR4xJTrwLjP",
        "outputId": "627c2678-ccc4-40b4-ddc8-3f490e6196e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor addition\n",
        "a = torch.tensor([4, 8, 6], dtype=torch.float32)\n",
        "b = torch.tensor([5, 7, 9], dtype=torch.float32)\n",
        "# b = torch.tensor([3]) # broadcasted to meet shape requirements of a\n",
        "print(a + 10)\n",
        "print(a + b)\n",
        "print(a.add(b))\n",
        "# print(a.add_(b)) # inplace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJylDfEfzQF5",
        "outputId": "8dc7277f-f78c-4f6d-d4a9-ea3fafca128e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([14., 18., 16.])\n",
            "tensor([ 9., 15., 15.])\n",
            "tensor([ 9., 15., 15.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor subtraction\n",
        "print(a - 10)\n",
        "print(a - b)\n",
        "print(a.sub(b))\n",
        "# print(a.sub_(b)) # inplace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_cHCecC_zN1",
        "outputId": "e8b3bc2a-94e7-47bf-b6ae-5c474cfbd871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-6., -2., -4.])\n",
            "tensor([-1.,  1., -3.])\n",
            "tensor([-1.,  1., -3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor (element-wise) multiplication\n",
        "print(a * 4)\n",
        "print(a * b)\n",
        "print(a.mul(b))\n",
        "# print(a.mul_(b)) # inplace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk4vj6Ie_jnA",
        "outputId": "b2e8e412-5ddb-4bbd-a433-08e876b43a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([16., 32., 24.])\n",
            "tensor([20., 56., 54.])\n",
            "tensor([20., 56., 54.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor division\n",
        "print(a / 2)\n",
        "print(b / a)\n",
        "print(b.div(a))\n",
        "# print(b.div_(a)) # inplace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qf75-Gz_ouB",
        "outputId": "4a57711e-ecd8-425d-8115-7ba97ccd231e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 4., 3.])\n",
            "tensor([1.2500, 0.8750, 1.5000])\n",
            "tensor([1.2500, 0.8750, 1.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix multiplication (dot product)\n",
        "print(a @ b)\n",
        "print(a.matmul(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28qBtgndAmMO",
        "outputId": "a979059a-6efd-4261-db80-72ffdaa2b527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(130.)\n",
            "tensor(130.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix transpose\n",
        "# useful when inner dimensions for matrix multiplication do not match\n",
        "x = torch.rand(3, 4)\n",
        "print(x) # (3, 4)\n",
        "print(x.t()) # (4, 3)\n",
        "# print(x.t_()) # inplace "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz1mOAJaKZZw",
        "outputId": "794dce3a-7506-4d5b-b095-b80989d15378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7776, 0.7692, 0.6552, 0.3097],\n",
            "        [0.6931, 0.3628, 0.2188, 0.7973],\n",
            "        [0.8401, 0.0103, 0.8888, 0.4690]])\n",
            "tensor([[0.7776, 0.6931, 0.8401],\n",
            "        [0.7692, 0.3628, 0.0103],\n",
            "        [0.6552, 0.2188, 0.8888],\n",
            "        [0.3097, 0.7973, 0.4690]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor aggregation\n",
        "x = torch.arange(20)\n",
        "print(x)\n",
        "# return min element\n",
        "print(torch.min(x)) # 0\n",
        "print(x.min())\n",
        "# return max element\n",
        "print(torch.max(x)) # 19\n",
        "print(x.max())\n",
        "# return average of elements in the tensor\n",
        "print(torch.mean(x.type(torch.float32))) # torch.mean requires float input\n",
        "print(x.type(torch.float32).mean())\n",
        "# return the sum of elements in the tensor\n",
        "print(torch.sum(x))\n",
        "print(x.sum())\n",
        "# return the index of the max element in the tensor\n",
        "print(torch.argmax(x))\n",
        "print(x.argmax())\n",
        "# return the index of the min element in the tensor\n",
        "print(torch.argmin(x))\n",
        "print(x.argmin())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMYFIvT_yba_",
        "outputId": "a853fff8-e16d-49b9-c7f0-489178d5dd8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19])\n",
            "tensor(0)\n",
            "tensor(0)\n",
            "tensor(19)\n",
            "tensor(19)\n",
            "tensor(9.5000)\n",
            "tensor(9.5000)\n",
            "tensor(190)\n",
            "tensor(190)\n",
            "tensor(19)\n",
            "tensor(19)\n",
            "tensor(0)\n",
            "tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all below are used to fix issues with the shape or dimensionality of tensors we want to work with\n",
        "\n",
        "# reshaping tensors\n",
        "x = torch.arange(1., 13.)\n",
        "print(x)\n",
        "# new shapes must be compatible with total number of elements in the tensor\n",
        "print(x.reshape(3, 4))\n",
        "print(x.reshape(6, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0OAU8_M2FTe",
        "outputId": "f2c93e10-e111-4fb8-fdb0-fb723405f491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])\n",
            "tensor([[ 1.,  2.,  3.,  4.],\n",
            "        [ 5.,  6.,  7.,  8.],\n",
            "        [ 9., 10., 11., 12.]])\n",
            "tensor([[ 1.,  2.],\n",
            "        [ 3.,  4.],\n",
            "        [ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.],\n",
            "        [11., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing tensor view\n",
        "# similar to reshape except that new tensors shares the memory of the original tensor\n",
        "# changing output therefore changes the original input\n",
        "\n",
        "a = torch.arange(1, 21)\n",
        "print(a)\n",
        "b = a.view(10, 2)\n",
        "print(b)\n",
        "b[0] = b[0] * 0\n",
        "print(a) # first 2 elements of a have been set to zero even though b was operated on\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3q1NDct4P5Y",
        "outputId": "37354b45-f1fa-443b-a93a-ff7ee215b2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
            "        19, 20])\n",
            "tensor([[ 1,  2],\n",
            "        [ 3,  4],\n",
            "        [ 5,  6],\n",
            "        [ 7,  8],\n",
            "        [ 9, 10],\n",
            "        [11, 12],\n",
            "        [13, 14],\n",
            "        [15, 16],\n",
            "        [17, 18],\n",
            "        [19, 20]])\n",
            "tensor([ 0,  0,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
            "        19, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stacking tensors\n",
        "x = torch.tensor([1, 2, 3, 4])\n",
        "print(x.ndim)\n",
        "print(x.shape) # [4]\n",
        "# when dim = 0, stacking changes the first dimension of new tensor\n",
        "y = torch.stack([x, x, x], dim=0) # new shape is [3, 4]\n",
        "print(y)\n",
        "print(y.ndim)\n",
        "print(y.shape)\n",
        "# when dim = r-1, stacking changes the r-1 dimension of the new tensor where r is the rank of the output tensor\n",
        "z = torch.stack([x, x, x], dim=1) # new shape is [4, 3]\n",
        "print(z)\n",
        "print(z.ndim)\n",
        "print(z.shape)\n",
        "\n",
        "# vertical stacking\n",
        "v = torch.vstack([x, x, x])\n",
        "print(v) # new shape [2, 4]\n",
        "print(v.shape)\n",
        "\n",
        "# horizontal stacking\n",
        "h = torch.hstack([x, x, x])\n",
        "print(h) # new shape [8]\n",
        "print(h.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHnCTa1I5dBN",
        "outputId": "ef2a58bf-bb3e-471e-de53-d6a7e7edaac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "torch.Size([4])\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [1, 2, 3, 4],\n",
            "        [1, 2, 3, 4]])\n",
            "2\n",
            "torch.Size([3, 4])\n",
            "tensor([[1, 1, 1],\n",
            "        [2, 2, 2],\n",
            "        [3, 3, 3],\n",
            "        [4, 4, 4]])\n",
            "2\n",
            "torch.Size([4, 3])\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [1, 2, 3, 4],\n",
            "        [1, 2, 3, 4]])\n",
            "torch.Size([3, 4])\n",
            "tensor([1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4])\n",
            "torch.Size([12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# squeeze tensor shape\n",
        "# returns a tensor with all dimensions of size 1 removed\n",
        "# shares the same memory as the original tensor (like torch.view)\n",
        "r = torch.rand(2, 1, 4)\n",
        "print(r)\n",
        "print(r.shape)\n",
        "r_s = torch.squeeze(r)\n",
        "print(r_s)\n",
        "print(r_s.shape)\n",
        "\n",
        "# torch.squeeze(input, dim) can be used to squeeze tensor for a specific dim and ignore all other 1 dimensions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqosAqJY--ql",
        "outputId": "60dbaeb8-e800-4d97-8f33-c34166c9360c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.1865, 0.9208, 0.4622, 0.2939]],\n",
            "\n",
            "        [[0.7210, 0.7501, 0.5583, 0.9750]]])\n",
            "torch.Size([2, 1, 4])\n",
            "tensor([[0.1865, 0.9208, 0.4622, 0.2939],\n",
            "        [0.7210, 0.7501, 0.5583, 0.9750]])\n",
            "torch.Size([2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unsqueeze tensor shape\n",
        "# returns a new tensor with a dimension of 1 added for a specific dimension\n",
        "# shares the same memory as the original tensor (like torch.view)\n",
        "r = torch.rand(10)\n",
        "print(r)\n",
        "print(r.shape) # [10]\n",
        "r_us = torch.unsqueeze(r, dim=0)\n",
        "print(r_us)\n",
        "print(r_us.shape) # [1, 10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roQI56hlAJJ1",
        "outputId": "ec5e2bba-09ba-42a2-fabe-563e685b7123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9643, 0.1158, 0.8914, 0.4416, 0.4072, 0.8891, 0.2467, 0.0380, 0.3243,\n",
            "        0.9806])\n",
            "torch.Size([10])\n",
            "tensor([[0.9643, 0.1158, 0.8914, 0.4416, 0.4072, 0.8891, 0.2467, 0.0380, 0.3243,\n",
            "         0.9806]])\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# permute tensor dimensions\n",
        "# changes the shape of a tensor by reordering the lsit of dimensions\n",
        "# returns a view - shares the memory of original input tensor - same data\n",
        "x = torch.rand(1, 2, 3)\n",
        "print(x)\n",
        "print(x.shape)\n",
        "# create a new order for the dimensions of x\n",
        "y = torch.permute(x, [2, 1, 0]) # new shape for x of [3, 2, 1]\n",
        "print(y)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0rovhvlCiPK",
        "outputId": "c3f183cd-2264-4cc7-a263-23179a60cabd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.9760, 0.9335, 0.3542],\n",
            "         [0.8364, 0.7478, 0.0047]]])\n",
            "torch.Size([1, 2, 3])\n",
            "tensor([[[0.9760],\n",
            "         [0.8364]],\n",
            "\n",
            "        [[0.9335],\n",
            "         [0.7478]],\n",
            "\n",
            "        [[0.3542],\n",
            "         [0.0047]]])\n",
            "torch.Size([3, 2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# indexing\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "print(x)\n",
        "print(x[0][2][2]) # 9\n",
        "print(x[:, :, 2]) # [3, 6, 9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o2F7piLCi3N",
        "outputId": "1eb960a3-5c1f-47ab-918b-2108a3e5dac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]])\n",
            "tensor(9)\n",
            "tensor([[3, 6, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# convert numpy array to tensor\n",
        "x = np.arange(1.0, 10.0) # default float type is float64\n",
        "print(x)\n",
        "y = torch.from_numpy(x) # tensor becomes float64, new tensor in memory\n",
        "print(y)\n",
        "\n",
        "# convert tensor to numpy array\n",
        "z = torch.ones(10) # default float type is float 32\n",
        "print(z)\n",
        "a = z.numpy() # numpy array becomes float32, new array in memory\n",
        "print(a)\n",
        "\n",
        "# beware the default type for numpy arrays and tensors, converting between each reflects the default type of the original structure\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBQ3buAbJANv",
        "outputId": "392431bd-c497-410c-b93f-d30ee5c7910e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
            "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reproducibility - removing randomness\n",
        "# ensure easier testing and experimentation of neural networks by controlling the value of parameters during each iteration\n",
        "# e.g. every random initilaization of a parameter will be different between runs\n",
        "import torch\n",
        "\n",
        "torch.manual_seed(10) # set then manual seed before each block of (random) code to get a deterministic result\n",
        "A = torch.rand(3, 3)\n",
        "torch.manual_seed(10) # identical seeds\n",
        "B = torch.rand(3, 3)\n",
        "print(A)\n",
        "print(B)\n",
        "print(A == B)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtFv_57LOV6A",
        "outputId": "97a86dd0-5b9a-4f9a-9bab-d4055c484127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4581, 0.4829, 0.3125],\n",
            "        [0.6150, 0.2139, 0.4118],\n",
            "        [0.6938, 0.9693, 0.6178]])\n",
            "tensor([[0.4581, 0.4829, 0.3125],\n",
            "        [0.6150, 0.2139, 0.4118],\n",
            "        [0.6938, 0.9693, 0.6178]])\n",
            "tensor([[True, True, True],\n",
            "        [True, True, True],\n",
            "        [True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU agnostic code\n",
        "# run the code regardless of which device is available\n",
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' # set the device to allocate pytorch objects on\n",
        "if device == 'cuda':\n",
        "  print(torch.cuda.device_count()) # how many GPUs are connected\n",
        "  !nvidia-smi # print information about the GPU available\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O7A_9xVR48x",
        "outputId": "4997c42d-958c-4b38-f8e1-bc4fb3d384d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Fri Nov  4 11:18:56 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0    30W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# allocating models and tensors onto a GPU leads to faster computations\n",
        "\n",
        "# move tensor to gpu with the to() method (if available)\n",
        "x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
        "y = x.to(device)\n",
        "print(y)\n",
        "\n",
        "# numpy cannot be used with objects allocated on GPUs\n",
        "# objects must be re-allocated to the CPU first before numpy operations using .cpu() method\n",
        "z = y.cpu().numpy()\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWqvwN2TVIye",
        "outputId": "c373d890-6bf3-4052-8bba-b60dcf65ee5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]], device='cuda:0')\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n"
          ]
        }
      ]
    }
  ]
}